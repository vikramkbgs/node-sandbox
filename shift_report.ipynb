{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import requests\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValues(tagList, start ,end):\n",
    "        url = \"https://data.exactspace.co/kairosapi/api/v1/datapoints/query\"\n",
    "        d = {\n",
    "            \"metrics\": [\n",
    "                {\n",
    "                    \"tags\": {},\n",
    "                    \"name\": \"\"\n",
    "                }\n",
    "            ],\n",
    "            \"plugins\": [],\n",
    "            \"cache_time\": 0,\n",
    "            \"cache_time\": 0,\n",
    "            \"start_absolute\": start,\n",
    "            \"end_absolute\": end\n",
    "        }\n",
    "        finalDF = pd.DataFrame()\n",
    "        for tag in tagList:\n",
    "            d['metrics'][0]['name'] = tag\n",
    "            res = requests.post(url=url, json=d)\n",
    "            values = json.loads(res.content)\n",
    "            df = pd.DataFrame(values[\"queries\"][0][\"results\"][0]['values'], columns=['time', values[\"queries\"][0][\"results\"][0]['name']])\n",
    "            finalDF = pd.concat([finalDF, df], axis=1)\n",
    "\n",
    "        finalDF = finalDF.loc[:, ~finalDF.columns.duplicated()]\n",
    "        finalDF.dropna(subset=['time'], inplace=True)\n",
    "        # finalDF['time'] = pd.to_datetime(finalDF['time'], unit='ms').dt.strftime('%d-%m-%y %H:%M:%S')\n",
    "        return finalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mld_2_anode_status(start, end):\n",
    "    tags= [\n",
    "            'GAP_GAP04.PLC04.MLD2_DATA_Anode_Geometric',\n",
    "            'GAP_GAP03.PLC03.SCHENCK2_FEED_RATE',\n",
    "            'GAP_GAP04.PLC04.MLD2_DATA_Anode_Number'\n",
    "        ]\n",
    "    \n",
    "    temp_df = pd.DataFrame(columns=['time'])\n",
    "    temp_df.loc[0, 'time'] = start  # Insert 42 into 'Good' column at index 0\n",
    "    temp_df.loc[1, 'time'] = end\n",
    "    temp_df['time'] += (5 * 60 + 30) * 60 * 1000\n",
    "    temp_df['date'] = pd.to_datetime(temp_df['time'], unit='ms')\n",
    "\n",
    "    mld_2_df=getValues(tags, start, end)\n",
    "    \n",
    "    mld_2_df = mld_2_df.dropna()\n",
    "    mld_2_df = mld_2_df[(mld_2_df['GAP_GAP03.PLC03.SCHENCK2_FEED_RATE'] >= 4000) & (mld_2_df['GAP_GAP03.PLC03.SCHENCK2_FEED_RATE'] < 6700) \n",
    "        & (mld_2_df['GAP_GAP04.PLC04.MLD2_DATA_Anode_Geometric'] >= 1.56) & (mld_2_df['GAP_GAP04.PLC04.MLD2_DATA_Anode_Geometric'] <= 1.69)]\n",
    "    \n",
    "    mld_2_df = mld_2_df[mld_2_df['GAP_GAP04.PLC04.MLD2_DATA_Anode_Number'] % 1 == 0]\n",
    "    mld_2_df['GAP_GAP04.PLC04.MLD2_DATA_Anode_Number'] = mld_2_df['GAP_GAP04.PLC04.MLD2_DATA_Anode_Number'].astype(int)\n",
    "\n",
    "    # Find consecutive duplicate values in the column and mark them for removal\n",
    "    mld_2_df['to_remove'] = mld_2_df['GAP_GAP04.PLC04.MLD2_DATA_Anode_Number'] == mld_2_df['GAP_GAP04.PLC04.MLD2_DATA_Anode_Number'].shift(1)\n",
    "\n",
    "    mld_2_df = mld_2_df[mld_2_df['to_remove'] != True]\n",
    "    \n",
    "    mld_2_df.reset_index(drop=True, inplace=True)\n",
    "    # print(mld_2_df)\n",
    "    # Assuming df is your DataFrame\n",
    "    # Convert the 'time' column to datetime format\n",
    "    mld_2_df['time'] += (5 * 60 + 30) * 60 * 1000\n",
    "    mld_2_df['date'] = pd.to_datetime(mld_2_df['time'], unit='ms')\n",
    "\n",
    "    # Define conditions for categorizing 'GAP_GAP04.PLC04.MLD1_DATA_Anode_Geometric'\n",
    "    condition_better = mld_2_df['GAP_GAP04.PLC04.MLD2_DATA_Anode_Geometric'] >= 1.66\n",
    "    condition_good = (mld_2_df['GAP_GAP04.PLC04.MLD2_DATA_Anode_Geometric'] >= 1.65) & (mld_2_df['GAP_GAP04.PLC04.MLD2_DATA_Anode_Geometric'] < 1.66)\n",
    "    condition_bad = mld_2_df['GAP_GAP04.PLC04.MLD2_DATA_Anode_Geometric'] < 1.65\n",
    "\n",
    "    # Create a new column 'category' based on conditions\n",
    "    mld_2_df['category'] = 'Undefined'\n",
    "    mld_2_df.loc[condition_better, 'category'] = 'Better'\n",
    "    mld_2_df.loc[condition_good, 'category'] = 'Good'\n",
    "    mld_2_df.loc[condition_bad, 'category'] = 'Bad'\n",
    "\n",
    "    # Create an empty DataFrame with columns\n",
    "    hourly_counts = pd.DataFrame(columns=['Bad', 'Better', 'Good', 'time'])\n",
    "\n",
    "    # Group by hour and category, then count occurrences\n",
    "    hourly_counts = mld_2_df.groupby([mld_2_df['date'].dt.floor('H'), 'category']).size().unstack(fill_value=0)\n",
    "\n",
    "    complete_hourly_index = pd.date_range(temp_df['date'].min(), temp_df['date'].max(), freq='H')\n",
    "    reference_df = pd.DataFrame(complete_hourly_index, columns=['date'])\n",
    "\n",
    "    # Add columns for 'Good', 'Better', and 'Bad' with zeros\n",
    "    reference_df['Good'] = 0\n",
    "    reference_df['Better'] = 0\n",
    "    reference_df['Bad'] = 0\n",
    "\n",
    "    missing_categories = set(['Bad', 'Better', 'Good']) - set(hourly_counts.columns)\n",
    "    for category in missing_categories:\n",
    "            hourly_counts[category] = 0\n",
    "\n",
    "    hourly_counts = pd.merge(reference_df, hourly_counts, how='left', on=['date'])\n",
    "    hourly_counts = hourly_counts[['date', 'Good_y', 'Better_y', 'Bad_y']]\n",
    "    hourly_counts = hourly_counts.rename(columns={'Good_y': 'Good', 'Better_y': 'Better', 'Bad_y':'Bad'})\n",
    "\n",
    "    hourly_counts = hourly_counts.fillna(0)\n",
    "    return hourly_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 1701369000000\n",
    "end = 1703961000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_counts = mld_2_anode_status(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1015.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_counts['Bad'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mld_1_anode_status(start, end):\n",
    "        tags= [\n",
    "                'GAP_GAP04.PLC04.MLD1_DATA_Anode_Geometric',\n",
    "                'GAP_GAP03.PLC03.SCHENCK2_FEED_RATE',\n",
    "                'GAP_GAP04.PLC04.MLD1_DATA_Anode_Number'\n",
    "            ]\n",
    "\n",
    "        temp_df = pd.DataFrame(columns=['time'])\n",
    "        temp_df.loc[0, 'time'] = start  # Insert 42 into 'Good' column at index 0\n",
    "        temp_df.loc[1, 'time'] = end\n",
    "        temp_df['time'] += (5 * 60 + 30) * 60 * 1000\n",
    "        temp_df['date'] = pd.to_datetime(temp_df['time'], unit='ms')\n",
    "\n",
    "        mld_1_df=getValues(tags, start, end)\n",
    "\n",
    "        mld_1_df = mld_1_df.dropna()\n",
    "        mld_1_df = mld_1_df[(mld_1_df['GAP_GAP03.PLC03.SCHENCK2_FEED_RATE'] >= 4000) & (mld_1_df['GAP_GAP03.PLC03.SCHENCK2_FEED_RATE'] < 6700) \n",
    "            & (mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Geometric'] >= 1.56) & (mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Geometric'] <= 1.69)]\n",
    "\n",
    "        mld_1_df = mld_1_df[mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Number'] % 1 == 0]\n",
    "        mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Number'] = mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Number'].astype(int)\n",
    "\n",
    "        # Find consecutive duplicate values in the column and mark them for removal\n",
    "        mld_1_df['to_remove'] = mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Number'] == mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Number'].shift(1)\n",
    "\n",
    "        mld_1_df = mld_1_df[mld_1_df['to_remove'] != True]\n",
    "\n",
    "        mld_1_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "        mld_1_df['time'] += (5 * 60 + 30) * 60 * 1000\n",
    "        mld_1_df['date'] = pd.to_datetime(mld_1_df['time'], unit='ms')\n",
    "\n",
    "        # Define conditions for categorizing 'GAP_GAP04.PLC04.MLD1_DATA_Anode_Geometric'\n",
    "        condition_better = mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Geometric'] >= 1.66\n",
    "        condition_good = (mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Geometric'] >= 1.65) & (mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Geometric'] < 1.66)\n",
    "        condition_bad = mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Geometric'] < 1.65\n",
    "\n",
    "        # Create a new column 'category' based on conditions\n",
    "        mld_1_df['category'] = 'Undefined'\n",
    "        mld_1_df.loc[condition_better, 'category'] = 'Better'\n",
    "        mld_1_df.loc[condition_good, 'category'] = 'Good'\n",
    "        mld_1_df.loc[condition_bad, 'category'] = 'Bad'\n",
    "\n",
    "        # Create an empty DataFrame with columns\n",
    "        hourly_counts = pd.DataFrame(columns=['Bad', 'Better', 'Good', 'time'])\n",
    "\n",
    "        # Group by hour and category, then count occurrences\n",
    "        hourly_counts = mld_1_df.groupby([mld_1_df['date'].dt.floor('H'), 'category']).size().unstack(fill_value=0)\n",
    "\n",
    "        complete_hourly_index = pd.date_range(temp_df['date'].min(), temp_df['date'].max(), freq='H')\n",
    "        reference_df = pd.DataFrame(complete_hourly_index, columns=['date'])\n",
    "\n",
    "        # Add columns for 'Good', 'Better', and 'Bad' with zeros\n",
    "        reference_df['Good'] = 0\n",
    "        reference_df['Better'] = 0\n",
    "        reference_df['Bad'] = 0\n",
    "\n",
    "        missing_categories = set(['Bad', 'Better', 'Good']) - set(hourly_counts.columns)\n",
    "        for category in missing_categories:\n",
    "                hourly_counts[category] = 0\n",
    "\n",
    "        hourly_counts = pd.merge(reference_df, hourly_counts, how='left', on=['date'])\n",
    "        hourly_counts = hourly_counts[['date', 'Good_y', 'Better_y', 'Bad_y']]\n",
    "        hourly_counts = hourly_counts.rename(columns={'Good_y': 'Good', 'Better_y': 'Better', 'Bad_y':'Bad'})\n",
    "\n",
    "        hourly_counts = hourly_counts.fillna(0)\n",
    "        return hourly_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_counts = mld_1_anode_status(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Good</th>\n",
       "      <th>Better</th>\n",
       "      <th>Bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-01 00:00:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-01 01:00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-01 02:00:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-01 03:00:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-01 04:00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  Good  Better  Bad\n",
       "0 2023-12-01 00:00:00  13.0     4.0  0.0\n",
       "1 2023-12-01 01:00:00   8.0     7.0  0.0\n",
       "2 2023-12-01 02:00:00  13.0     4.0  0.0\n",
       "3 2023-12-01 03:00:00  11.0     5.0  0.0\n",
       "4 2023-12-01 04:00:00   8.0     4.0  5.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Good</th>\n",
       "      <th>Better</th>\n",
       "      <th>Bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>2023-12-30 20:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>2023-12-30 21:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>2023-12-30 22:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>2023-12-30 23:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>2023-12-31 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date  Good  Better  Bad\n",
       "716 2023-12-30 20:00:00   0.0     0.0  0.0\n",
       "717 2023-12-30 21:00:00   0.0     0.0  0.0\n",
       "718 2023-12-30 22:00:00   0.0     0.0  0.0\n",
       "719 2023-12-30 23:00:00   0.0     0.0  0.0\n",
       "720 2023-12-31 00:00:00   0.0     0.0  0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_counts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1184.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_counts['Bad'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpis_dashboard(start, end):\n",
    "        tags= [\n",
    "        'GAP_GAP04.PLC04.MLD1_DATA_Anode_Geometric',\n",
    "        'GAP_GAP03.PLC03.SCHENCK2_FEED_RATE',\n",
    "        'GAP_GAP04.PLC04.MLD1_DATA_Anode_Number',\n",
    "        'GAP_GAP04.PLC04.MLD1_DATA_Anode_Weight',\n",
    "        'GAP_GAP04.PLC04.MLD1_DATA_Anode_Height',\n",
    "        'GAP_GAP04.PLC04.MLD1_DATA_Anode_Dry_Density'\n",
    "        ]\n",
    "\n",
    "        temp_df = pd.DataFrame(columns=['time'])\n",
    "        temp_df.loc[0, 'time'] = start  # Insert 42 into 'Good' column at index 0\n",
    "        temp_df.loc[1, 'time'] = end\n",
    "        temp_df['time'] += (5 * 60 + 30) * 60 * 1000\n",
    "        temp_df['date'] = pd.to_datetime(temp_df['time'], unit='ms')\n",
    "\n",
    "        mld_1_df=getValues(tags, start, end)\n",
    "\n",
    "        mld_1_df = mld_1_df.dropna()\n",
    "        mld_1_df = mld_1_df[(mld_1_df['GAP_GAP03.PLC03.SCHENCK2_FEED_RATE'] >= 4000) & (mld_1_df['GAP_GAP03.PLC03.SCHENCK2_FEED_RATE'] < 6700) \n",
    "        & (mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Geometric'] >= 1.56) & (mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Geometric'] <= 1.69)]\n",
    "\n",
    "        mld_1_df = mld_1_df[mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Number'] % 1 == 0]\n",
    "        mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Number'] = mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Number'].astype(int)\n",
    "\n",
    "        # Find consecutive duplicate values in the column and mark them for removal\n",
    "        mld_1_df['to_remove'] = mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Number'] == mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Number'].shift(1)\n",
    "\n",
    "        mld_1_df = mld_1_df[mld_1_df['to_remove'] != True]\n",
    "\n",
    "        mld_1_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "        mld_1_df['time'] += (5 * 60 + 30) * 60 * 1000\n",
    "        mld_1_df['date'] = pd.to_datetime(mld_1_df['time'], unit='ms')\n",
    "        mld_1_df.set_index('date', inplace=True)\n",
    "\n",
    "\n",
    "        columns_of_interest = [\n",
    "            'GAP_GAP04.PLC04.MLD1_DATA_Anode_Weight',\n",
    "            'GAP_GAP04.PLC04.MLD1_DATA_Anode_Dry_Density',\n",
    "            'GAP_GAP04.PLC04.MLD1_DATA_Anode_Geometric',\n",
    "            'GAP_GAP04.PLC04.MLD1_DATA_Anode_Height'\n",
    "        ]\n",
    "\n",
    "        # Calculate hourly mean for multiple columns\n",
    "        hourly_mean = mld_1_df[columns_of_interest].resample('H').mean()\n",
    "        hourly_std = mld_1_df[columns_of_interest].resample('H').std()\n",
    "        hourly_std = hourly_std.round(3)\n",
    "        hourly_mean = hourly_mean.round(3)\n",
    "\n",
    "        hourly_std.reset_index(inplace=True)\n",
    "        hourly_mean.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "        complete_hourly_index = pd.date_range(temp_df['date'].min(), temp_df['date'].max(), freq='H')\n",
    "        reference_df = pd.DataFrame(complete_hourly_index, columns=['date'])\n",
    "\n",
    "        hourly_mean = pd.merge(reference_df, hourly_mean, how='left', on=['date'])\n",
    "        hourly_std = pd.merge(reference_df, hourly_std, how='left', on=['date'])\n",
    "        global test_df\n",
    "        test_df = hourly_std.copy()\n",
    "\n",
    "        missing_categories1 = set(['GAP_GAP04.PLC04.MLD1_DATA_Anode_Weight',\n",
    "            'GAP_GAP04.PLC04.MLD1_DATA_Anode_Dry_Density',\n",
    "            'GAP_GAP04.PLC04.MLD1_DATA_Anode_Geometric',\n",
    "            'GAP_GAP04.PLC04.MLD1_DATA_Anode_Height']) - set(hourly_mean.columns)\n",
    "\n",
    "        missing_categories2 = set(['GAP_GAP04.PLC04.MLD1_DATA_Anode_Weight',\n",
    "            'GAP_GAP04.PLC04.MLD1_DATA_Anode_Dry_Density',\n",
    "            'GAP_GAP04.PLC04.MLD1_DATA_Anode_Geometric',\n",
    "            'GAP_GAP04.PLC04.MLD1_DATA_Anode_Height']) - set(hourly_std.columns)\n",
    "\n",
    "        for category in missing_categories1:\n",
    "                hourly_mean[category] = 0\n",
    "\n",
    "        for category in missing_categories2:\n",
    "                hourly_std[category] = 0\n",
    "\n",
    "        hourly_mean = hourly_mean.fillna(0)\n",
    "        hourly_std = hourly_std.fillna(0)\n",
    "\n",
    "        hourly_mean.set_index('date', inplace=True)\n",
    "        hourly_std.set_index('date', inplace=True)\n",
    "\n",
    "        # Convert the index to epoch format\n",
    "        hourly_mean[\"time\"] = hourly_mean.index.astype(int) // 10**6  \n",
    "        hourly_mean[\"time\"] -= (5 * 60 + 30) * 60 * 1000\n",
    "\n",
    "        hourly_std[\"time\"] = hourly_std.index.astype(int) // 10**6  \n",
    "        hourly_std[\"time\"] -= (5 * 60 + 30) * 60 * 1000\n",
    "\n",
    "        return hourly_mean, hourly_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vikra\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:87: FutureWarning: casting datetime64[ns] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
      "c:\\Users\\vikra\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:90: FutureWarning: casting datetime64[ns] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n"
     ]
    }
   ],
   "source": [
    "hourly_means, hourly_std = kpis_dashboard(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAP_GAP04.PLC04.MLD1_DATA_Anode_Weight         9.619089e+00\n",
       "GAP_GAP04.PLC04.MLD1_DATA_Anode_Dry_Density    6.083784e-03\n",
       "GAP_GAP04.PLC04.MLD1_DATA_Anode_Geometric      5.670270e-03\n",
       "GAP_GAP04.PLC04.MLD1_DATA_Anode_Height         4.329105e+00\n",
       "time                                           1.702569e+12\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_std[hourly_std['GAP_GAP04.PLC04.MLD1_DATA_Anode_Weight'] > 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_parameters(start, end):\n",
    "\n",
    "        tags= [\n",
    "        'GAP_GAP04.PLC04.MLD1_DATA_Anode_Geometric',\n",
    "        'GAP_GAP03.PLC03.SCHENCK2_FEED_RATE',\n",
    "        'GAP_GAP04.PLC04.MLD1_DATA_Anode_Number',\n",
    "        'GAP_GAP01.PLC01.U362_E020_MVF_01_ACTRL_AUTOSPEEDREF',\n",
    "        'GAP_GAP01.PLC01._362_E020_ZT_01.PV',\n",
    "        'GAP_GAP03.PLC03.J362_J150_JT_01_PW01_IN',\n",
    "        'GAP_GAP04.PLC04.EU2_DATA_Cooler_Load',\n",
    "        'GAP_GAP03.PLC03.J362_J155_JT_01_PW01_IN',\n",
    "        'GAP_GAP04.PLC04.MLD2_DATA_Paste_Eval_Temp',\n",
    "        'GAP_GAP04.PLC04.K363_K040A_MVF_01_VTK',\n",
    "        'GAP_GAP04.PLC04.MLD1_DATA_Anode_Vaccum_Pres',\n",
    "        'GAP_GAP04.PLC04.MLD2_DATA_Anode_Counter_Pres',\n",
    "        'GAP_GAP03.PLC03.U362_J130_TIT_01_PV',\n",
    "        'GAP_GAP02.PLC02._362_H120_TIT_01.PV',\n",
    "        'GAP_GAP03.PLC03._362_J150_WIT_01.PV'\n",
    "        ]\n",
    "\n",
    "        temp_df = pd.DataFrame(columns=['time'])\n",
    "        temp_df.loc[0, 'time'] = start  \n",
    "        temp_df.loc[1, 'time'] = end\n",
    "        temp_df['time'] += (5 * 60 + 30) * 60 * 1000\n",
    "        temp_df['date'] = pd.to_datetime(temp_df['time'], unit='ms')\n",
    "\n",
    "        mld_1_df=getValues(tags, start, end)\n",
    "\n",
    "        mld_1_df = mld_1_df.dropna()\n",
    "        mld_1_df = mld_1_df[(mld_1_df['GAP_GAP03.PLC03.SCHENCK2_FEED_RATE'] >= 4000) & (mld_1_df['GAP_GAP03.PLC03.SCHENCK2_FEED_RATE'] < 6700) \n",
    "        & (mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Geometric'] >= 1.56) & (mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Geometric'] <= 1.69)]\n",
    "\n",
    "        mld_1_df = mld_1_df[mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Number'] % 1 == 0]\n",
    "        mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Number'] = mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Number'].astype(int)\n",
    "        # Find consecutive duplicate values in the column and mark them for removal\n",
    "        mld_1_df['to_remove'] = mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Number'] == mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Number'].shift(1)\n",
    "\n",
    "        mld_1_df = mld_1_df[mld_1_df['to_remove'] != True]\n",
    "\n",
    "        mld_1_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "        mld_1_df['time'] += (5 * 60 + 30) * 60 * 1000\n",
    "        mld_1_df['date'] = pd.to_datetime(mld_1_df['time'], unit='ms')\n",
    "        mld_1_df.set_index('date', inplace=True)\n",
    "\n",
    "\n",
    "        columns_of_interest = [\n",
    "        'GAP_GAP01.PLC01.U362_E020_MVF_01_ACTRL_AUTOSPEEDREF',\n",
    "        'GAP_GAP01.PLC01._362_E020_ZT_01.PV',\n",
    "        'GAP_GAP03.PLC03.J362_J150_JT_01_PW01_IN',\n",
    "        'GAP_GAP04.PLC04.EU2_DATA_Cooler_Load',\n",
    "        'GAP_GAP03.PLC03.J362_J155_JT_01_PW01_IN',\n",
    "        'GAP_GAP04.PLC04.MLD2_DATA_Paste_Eval_Temp',\n",
    "        'GAP_GAP04.PLC04.K363_K040A_MVF_01_VTK',\n",
    "        'GAP_GAP04.PLC04.MLD1_DATA_Anode_Vaccum_Pres',\n",
    "        'GAP_GAP04.PLC04.MLD2_DATA_Anode_Counter_Pres',\n",
    "        'GAP_GAP03.PLC03.U362_J130_TIT_01_PV',\n",
    "        'GAP_GAP02.PLC02._362_H120_TIT_01.PV',\n",
    "        'GAP_GAP03.PLC03._362_J150_WIT_01.PV'\n",
    "        ]\n",
    "\n",
    "        # Calculate hourly mean for multiple columns\n",
    "        hourly_mean = mld_1_df[columns_of_interest].resample('H').mean()\n",
    "\n",
    "        hourly_mean = hourly_mean.round(3)\n",
    "\n",
    "        hourly_mean.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "        complete_hourly_index = pd.date_range(temp_df['date'].min(), temp_df['date'].max(), freq='H')\n",
    "        reference_df = pd.DataFrame(complete_hourly_index, columns=['date'])\n",
    "\n",
    "        hourly_mean = pd.merge(reference_df, hourly_mean, how='left', on=['date'])\n",
    "\n",
    "        missing_categories = set(['GAP_GAP01.PLC01.U362_E020_MVF_01_ACTRL_AUTOSPEEDREF',\n",
    "        'GAP_GAP01.PLC01._362_E020_ZT_01.PV',\n",
    "        'GAP_GAP03.PLC03.J362_J150_JT_01_PW01_IN',\n",
    "        'GAP_GAP04.PLC04.EU2_DATA_Cooler_Load',\n",
    "        'GAP_GAP03.PLC03.J362_J155_JT_01_PW01_IN',\n",
    "        'GAP_GAP04.PLC04.MLD2_DATA_Paste_Eval_Temp',\n",
    "        'GAP_GAP04.PLC04.K363_K040A_MVF_01_VTK',\n",
    "        'GAP_GAP04.PLC04.MLD1_DATA_Anode_Vaccum_Pres',\n",
    "        'GAP_GAP04.PLC04.MLD2_DATA_Anode_Counter_Pres',\n",
    "        'GAP_GAP03.PLC03.U362_J130_TIT_01_PV',\n",
    "        'GAP_GAP02.PLC02._362_H120_TIT_01.PV',\n",
    "        'GAP_GAP03.PLC03._362_J150_WIT_01.PV']) - set(hourly_mean.columns)\n",
    "\n",
    "        for category in missing_categories:\n",
    "                hourly_mean[category] = 0\n",
    "        hourly_mean = hourly_mean.fillna(0)\n",
    "        return hourly_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_means = process_parameters(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vikra\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GAP_GAP01.PLC01.U362_E020_MVF_01_ACTRL_AUTOSPEEDREF      55.181419\n",
       "GAP_GAP01.PLC01._362_E020_ZT_01.PV                       74.150357\n",
       "GAP_GAP03.PLC03.J362_J150_JT_01_PW01_IN                  98.060344\n",
       "GAP_GAP04.PLC04.EU2_DATA_Cooler_Load                      0.000000\n",
       "GAP_GAP03.PLC03.J362_J155_JT_01_PW01_IN                  96.608094\n",
       "GAP_GAP04.PLC04.MLD2_DATA_Paste_Eval_Temp               175.549602\n",
       "GAP_GAP04.PLC04.K363_K040A_MVF_01_VTK                    52.679685\n",
       "GAP_GAP04.PLC04.MLD1_DATA_Anode_Vaccum_Pres              98.637076\n",
       "GAP_GAP04.PLC04.MLD2_DATA_Anode_Counter_Pres              1.324250\n",
       "GAP_GAP03.PLC03.U362_J130_TIT_01_PV                     179.390307\n",
       "GAP_GAP02.PLC02._362_H120_TIT_01.PV                     233.479034\n",
       "GAP_GAP03.PLC03._362_J150_WIT_01.PV                    2532.920021\n",
       "dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_means[hourly_means['GAP_GAP01.PLC01.U362_E020_MVF_01_ACTRL_AUTOSPEEDREF'] > 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_anode_rhodax_speed_mean = hourly_mean[['time', 'GAP_GAP01.PLC01.U362_E020_MVF_01_ACTRL_AUTOSPEEDREF']].values.tolist()\n",
    "gap_anode_Rhodax_gap_mean = hourly_mean[['time', 'GAP_GAP01.PLC01._362_E020_ZT_01.PV']].values.tolist()\n",
    "gap_anode_Cooler_Load_mean = hourly_mean[['time', 'GAP_GAP04.PLC04.EU2_DATA_Cooler_Load']].values.tolist()\n",
    "gap_anode_Cooler_Rotor_Power_mean = hourly_mean[['time', 'GAP_GAP03.PLC03.J362_J155_JT_01_PW01_IN']].values.tolist()\n",
    "gap_anode_Paste_Temp_mean = hourly_mean[['time', 'GAP_GAP04.PLC04.MLD2_DATA_Paste_Eval_Temp']].values.tolist()\n",
    "gap_anode_Vibration_Time_mean = hourly_mean[['time', 'GAP_GAP04.PLC04.K363_K040A_MVF_01_VTK']].values.tolist()\n",
    "gap_anode_Counter_Pressure_mean = hourly_mean[['time', 'GAP_GAP04.PLC04.MLD2_DATA_Anode_Counter_Pres']].values.tolist()\n",
    "gap_anode_vacum_pressure_mean = hourly_mean[['time', 'GAP_GAP04.PLC04.MLD1_DATA_Anode_Vaccum_Pres']].values.tolist()\n",
    "gap_anode_PH_Screw_Temp_mean = hourly_mean[['time', 'GAP_GAP03.PLC03.U362_J130_TIT_01_PV']].values.tolist()\n",
    "gap_anode_Pitch_Temp_mean = hourly_mean[['time', 'GAP_GAP02.PLC02._362_H120_TIT_01.PV']].values.tolist()\n",
    "gap_anode_Mixer_Load_mean = hourly_mean[['time', 'GAP_GAP03.PLC03._362_J150_WIT_01.PV']].values.tolist()\n",
    "gap_anode_Mixer_Rotor_Power_mean = hourly_mean[['time', 'GAP_GAP03.PLC03.J362_J150_JT_01_PW01_IN']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_parameters(start, end):\n",
    "        tags= [\n",
    "        'GAP_GAP04.PLC04.MLD1_DATA_Anode_Geometric',\n",
    "        'GAP_GAP03.PLC03.SCHENCK2_FEED_RATE',\n",
    "        'GAP_GAP04.PLC04.MLD1_DATA_Anode_Number',\n",
    "        'GAP_GAP03.PLC03.ACTUAL_FORMULA.KGS',\n",
    "        'GAP_GAP03.PLC03.ACTUAL_FORMULA.KLP',\n",
    "        'GAP_GAP04.PLC04.U363_K145_FIT_01_PV',\n",
    "        'GAP_GAP03.PLC03.ACTUAL_FORMULA.KFR',\n",
    "        'GAP_GAP03.PLC03.ACTUAL_FORMULA_KBS'\n",
    "        ]\n",
    "\n",
    "        temp_df = pd.DataFrame(columns=['time'])\n",
    "        temp_df.loc[0, 'time'] = start  \n",
    "        temp_df.loc[1, 'time'] = end\n",
    "        temp_df['time'] += (5 * 60 + 30) * 60 * 1000\n",
    "        temp_df['date'] = pd.to_datetime(temp_df['time'], unit='ms')\n",
    "\n",
    "        mld_1_df=getValues(tags, start, end)\n",
    "\n",
    "        mld_1_df = mld_1_df.dropna()\n",
    "        mld_1_df = mld_1_df[(mld_1_df['GAP_GAP03.PLC03.SCHENCK2_FEED_RATE'] >= 4000) & (mld_1_df['GAP_GAP03.PLC03.SCHENCK2_FEED_RATE'] < 6700) \n",
    "        & (mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Geometric'] >= 1.56) & (mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Geometric'] <= 1.69)]\n",
    "\n",
    "        mld_1_df = mld_1_df[mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Number'] % 1 == 0]\n",
    "        mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Number'] = mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Number'].astype(int)\n",
    "\n",
    "        # Find consecutive duplicate values in the column and mark them for removal\n",
    "        mld_1_df['to_remove'] = mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Number'] == mld_1_df['GAP_GAP04.PLC04.MLD1_DATA_Anode_Number'].shift(1)\n",
    "\n",
    "        mld_1_df = mld_1_df[mld_1_df['to_remove'] != True]\n",
    "\n",
    "        mld_1_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "        mld_1_df['time'] += (5 * 60 + 30) * 60 * 1000\n",
    "        mld_1_df['date'] = pd.to_datetime(mld_1_df['time'], unit='ms')\n",
    "        mld_1_df.set_index('date', inplace=True)\n",
    "\n",
    "\n",
    "        columns_of_interest = [\n",
    "        'GAP_GAP03.PLC03.ACTUAL_FORMULA.KGS',\n",
    "        'GAP_GAP03.PLC03.ACTUAL_FORMULA.KLP',\n",
    "        'GAP_GAP04.PLC04.U363_K145_FIT_01_PV',\n",
    "        'GAP_GAP03.PLC03.ACTUAL_FORMULA.KFR',\n",
    "        'GAP_GAP03.PLC03.ACTUAL_FORMULA_KBS'\n",
    "        ]\n",
    "\n",
    "        # Calculate hourly mean for multiple columns\n",
    "        hourly_mean = mld_1_df[columns_of_interest].resample('H').mean()\n",
    "\n",
    "        hourly_mean = hourly_mean.round(3)\n",
    "\n",
    "        hourly_mean.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "        complete_hourly_index = pd.date_range(temp_df['date'].min(), temp_df['date'].max(), freq='H')\n",
    "        reference_df = pd.DataFrame(complete_hourly_index, columns=['date'])\n",
    "\n",
    "        hourly_mean = pd.merge(reference_df, hourly_mean, how='left', on=['date'])\n",
    "\n",
    "        missing_categories = set(['GAP_GAP03.PLC03.ACTUAL_FORMULA.KGS',\n",
    "        'GAP_GAP03.PLC03.ACTUAL_FORMULA.KLP',\n",
    "        'GAP_GAP04.PLC04.U363_K145_FIT_01_PV',\n",
    "        'GAP_GAP03.PLC03.ACTUAL_FORMULA.KFR',\n",
    "        'GAP_GAP03.PLC03.ACTUAL_FORMULA_KBS']) - set(hourly_mean.columns)\n",
    "\n",
    "        for category in missing_categories:\n",
    "                hourly_mean[category] = 0\n",
    "\n",
    "        hourly_mean = hourly_mean.fillna(0)\n",
    "        \n",
    "        return hourly_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_means = key_parameters(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>GAP_GAP03.PLC03.ACTUAL_FORMULA.KGS</th>\n",
       "      <th>GAP_GAP03.PLC03.ACTUAL_FORMULA.KLP</th>\n",
       "      <th>GAP_GAP04.PLC04.U363_K145_FIT_01_PV</th>\n",
       "      <th>GAP_GAP03.PLC03.ACTUAL_FORMULA.KFR</th>\n",
       "      <th>GAP_GAP03.PLC03.ACTUAL_FORMULA_KBS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-01 00:00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.850</td>\n",
       "      <td>3.496</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-01 01:00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.829</td>\n",
       "      <td>3.474</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-01 02:00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.850</td>\n",
       "      <td>0.173</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-01 03:00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.850</td>\n",
       "      <td>0.152</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-01 04:00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.850</td>\n",
       "      <td>0.282</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  GAP_GAP03.PLC03.ACTUAL_FORMULA.KGS  \\\n",
       "0 2023-12-01 00:00:00                                 3.0   \n",
       "1 2023-12-01 01:00:00                                 3.0   \n",
       "2 2023-12-01 02:00:00                                 3.0   \n",
       "3 2023-12-01 03:00:00                                 3.0   \n",
       "4 2023-12-01 04:00:00                                 3.0   \n",
       "\n",
       "   GAP_GAP03.PLC03.ACTUAL_FORMULA.KLP  GAP_GAP04.PLC04.U363_K145_FIT_01_PV  \\\n",
       "0                              12.850                                3.496   \n",
       "1                              12.829                                3.474   \n",
       "2                              12.850                                0.173   \n",
       "3                              12.850                                0.152   \n",
       "4                              12.850                                0.282   \n",
       "\n",
       "   GAP_GAP03.PLC03.ACTUAL_FORMULA.KFR  GAP_GAP03.PLC03.ACTUAL_FORMULA_KBS  \n",
       "0                                20.0                                25.0  \n",
       "1                                20.0                                25.0  \n",
       "2                                20.0                                25.0  \n",
       "3                                20.0                                25.0  \n",
       "4                                20.0                                25.0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_means.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vikra\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GAP_GAP03.PLC03.ACTUAL_FORMULA.KGS      3.000000\n",
       "GAP_GAP03.PLC03.ACTUAL_FORMULA.KLP     12.985118\n",
       "GAP_GAP04.PLC04.U363_K145_FIT_01_PV     0.423235\n",
       "GAP_GAP03.PLC03.ACTUAL_FORMULA.KFR     20.000000\n",
       "GAP_GAP03.PLC03.ACTUAL_FORMULA_KBS     24.361810\n",
       "dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_means[hourly_means['GAP_GAP03.PLC03.ACTUAL_FORMULA.KGS'] > 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_anode_fines_mean = hourly_mean[['time', 'GAP_GAP03.PLC03.ACTUAL_FORMULA.KFR']].values.tolist()\n",
    "gap_anode_paste_rejection_mean = hourly_mean[['time', 'GAP_GAP04.PLC04.U363_K145_FIT_01_PV']].values.tolist()\n",
    "gap_anode_pitch_mean = hourly_mean[['time', 'GAP_GAP03.PLC03.ACTUAL_FORMULA.KLP']].values.tolist()\n",
    "gap_anode_green_scrap_mean = hourly_mean[['time', 'GAP_GAP03.PLC03.ACTUAL_FORMULA.KGS']].values.tolist()\n",
    "gap_anode_green_butt_mean = hourly_mean[['time', 'GAP_GAP03.PLC03.ACTUAL_FORMULA_KBS']].values.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
